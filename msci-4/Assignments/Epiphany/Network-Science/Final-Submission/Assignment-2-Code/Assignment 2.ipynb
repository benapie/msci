{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "*Note that the networks in this exercise are all undirected.*\n",
    "\n",
    "*We recall some definitions and introduce some new ones.*\n",
    "\n",
    "*Let $d_{ij}$ be the distance (the length of the shortest path) between vertices $i$ to $j$.*\n",
    "\n",
    "*Then the closeness centrality of vertex $j$ is\n",
    "$\\operatorname{CC}(j)= \\frac{1}{\\sum_i d_{ij}}$.*\n",
    "\n",
    "*The nearness centrality of vertex $j$ is\n",
    "$\\operatorname{NC}(j)= \\sum_i \\frac{1}{d_{ij}}$.\n",
    "In both these definitions, the sums are over all vertices $i$, $i \\neq j$, in the network.*\n",
    "\n",
    "*The degree centrality of vertex $j$ is simply its degree (the number of neighbours it has) and is denoted $\\operatorname{DC}(j)$.*\n",
    "\n",
    "*The adjacency centrality of vertex $j$ is\n",
    "$\\operatorname{AC}(j)=\\frac{1}{d_j} \\sum_i \\frac{d_j - d_i}{d_j+d_i}$\n",
    "where the sum is over all vertices $i$ that are adjacent to $j$ and $d_i$ denotes the degree of a vertex.  (So $\\operatorname{DC}(j)$ and $d_j$ are different notations for the same measure.)*\n",
    "\n",
    "# Question 1\n",
    "\n",
    "1. *[5 marks]  Calculate the values of the four centrality measures defined above on each vertex in the network below.  (The diagram and the dictionary are two representations of the same network.)   Present your answer as four lists --- one for each centrality measure --- that gives the vertices and the calculated values ordered by those values.*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "network = {1: [4],\n",
    "           2: [4],\n",
    "           3: [4],\n",
    "           4: [1, 2, 3, 5, 6],\n",
    "           5: [4],\n",
    "           6: [4, 7, 8, 9, 10, 11],\n",
    "           7: [6, 8, 11],\n",
    "           8: [6, 7, 9, 11],\n",
    "           9: [6, 8, 10],\n",
    "           10: [6, 9, 11, 12],\n",
    "           11: [6, 7, 8, 10],\n",
    "           12: [10]}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, we import the required libraries."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "def print_status_bar(progress: float, block_count: int = 10) -> None:\n",
    "    clear_output(wait=True)\n",
    "    dark_string = \"▓\" * round(progress * block_count)\n",
    "    light_string = \"░\" * (block_count - len(dark_string))\n",
    "    print(f\"[{dark_string}{light_string}]\")\n",
    "\n",
    "\n",
    "def round_sig(x: float, sig: int = 3) -> str:\n",
    "    return \"%s\" % float(f\"%.{sig}g\" % x)\n",
    "\n",
    "\n",
    "def format_number(x: float, sig: int = 3) -> str:\n",
    "    out = round_sig(x, sig)\n",
    "    if x >= 0:\n",
    "        out = \" \" + out\n",
    "    return out\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below find the code for a breadth-first search function and a function to compute the distance matrix from an adjancency list."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def bfs(g: Dict[int, list[int]], node: int) -> Dict[int, int]:\n",
    "    vstd = {node: 0}\n",
    "    q = [node]\n",
    "    while q:\n",
    "        v = q.pop(0)\n",
    "        for nghbr in g[v]:\n",
    "            if nghbr not in vstd:\n",
    "                vstd[nghbr] = vstd[v] + 1\n",
    "                q.append(nghbr)\n",
    "    return vstd\n",
    "\n",
    "\n",
    "def compute_dst_mat(g: Dict[int, list[int]]) -> Dict[int, Dict[int, int]]:\n",
    "    dst_mat = {}\n",
    "    for v in g:\n",
    "        dst_mat[v] = bfs(g, v)\n",
    "    return dst_mat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We compute the distance matrix for our network."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "network_dst_mat = compute_dst_mat(network)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now define functions for the four measures."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def cc(distance_matrix: Dict[int, Dict[int, int]], node: int) -> float:\n",
    "    total = 0\n",
    "    for other_node in distance_matrix:\n",
    "        total += distance_matrix[node][other_node]\n",
    "    return 1 / total\n",
    "\n",
    "\n",
    "def nc(distance_matrix: Dict[int, Dict[int, int]], node: int) -> float:\n",
    "    total = 0\n",
    "    for other_node in distance_matrix:\n",
    "        if other_node == node:\n",
    "            continue\n",
    "        total += 1 / distance_matrix[node][other_node]\n",
    "    return total\n",
    "\n",
    "\n",
    "def dc(network: Dict[int, list[int]], node: int) -> int:\n",
    "    return len(network[node])\n",
    "\n",
    "\n",
    "def ac(network: Dict[int, list[int]], node: int) -> float:\n",
    "    total = 0\n",
    "    for neighbour in network[node]:\n",
    "        total += (dc(network, node) - dc(network, neighbour)) / (dc(network, node) + dc(network, neighbour))\n",
    "    total /= len(network[node])\n",
    "    return total"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now calculate the requested measures."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "measures = dict()\n",
    "\n",
    "for measure_name in [\"cc\", \"nc\", \"dc\", \"ac\"]:\n",
    "    measures[measure_name] = []\n",
    "for node in network:\n",
    "    measures[\"cc\"].append((node, cc(network_dst_mat, node)))\n",
    "    measures[\"nc\"].append((node, nc(network_dst_mat, node)))\n",
    "    measures[\"dc\"].append((node, dc(network, node)))\n",
    "    measures[\"ac\"].append((node, ac(network, node)))\n",
    "for measure_name in measures:\n",
    "    measures[measure_name] = sorted(measures[measure_name], key=lambda k: k[1], reverse=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And finally print them in a nice way."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________\n",
      "CC               NC               DC               AC               \n",
      "____________________________________________________________________\n",
      "6  :  0.0625     6  :  8.5        6  :  6.0        4  :  0.515      \n",
      "4  :  0.0556     4  :  7.83       4  :  5.0        6  :  0.226      \n",
      "10 :  0.0455     10 :  6.83       8  :  4.0        10 :  0.136      \n",
      "11 :  0.0455     11 :  6.83       10 :  4.0        8  :  0.0214     \n",
      "8  :  0.0435     8  :  6.67       11 :  4.0        11 : -0.0143     \n",
      "9  :  0.0435     9  :  6.33       7  :  3.0        7  : -0.206      \n",
      "7  :  0.0417     7  :  6.17       9  :  3.0        9  : -0.206      \n",
      "1  :  0.0357     1  :  4.92       1  :  1.0        12 : -0.6        \n",
      "2  :  0.0357     2  :  4.92       2  :  1.0        1  : -0.667      \n",
      "3  :  0.0357     3  :  4.92       3  :  1.0        2  : -0.667      \n",
      "5  :  0.0357     5  :  4.92       5  :  1.0        3  : -0.667      \n",
      "12 :  0.0312     12 :  4.5        12 :  1.0        5  : -0.667      \n",
      "____________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "column_width = 12\n",
    "print(\"_\" * ((5 * 4) + (column_width * 4)))\n",
    "print(\n",
    "    f\"{'CC'.ljust(5 + column_width)}{'NC'.ljust(5 + column_width)}{'DC'.ljust(5 + column_width)}{'AC'.ljust(5 + column_width)}\")\n",
    "print(\"_\" * ((5 * 4) + (column_width * 4)))\n",
    "for cc_tuple, nc_tuple, dc_tuple, ac_tuple in zip(measures[\"cc\"], measures[\"nc\"], measures[\"dc\"], measures[\"ac\"]):\n",
    "    cc_v = format_number(cc_tuple[1])\n",
    "    nc_v = format_number(nc_tuple[1])\n",
    "    dc_v = format_number(dc_tuple[1])\n",
    "    ac_v = format_number(ac_tuple[1])\n",
    "    print(\n",
    "        f\"{str(cc_tuple[0]).ljust(3)}: {str(cc_v).ljust(column_width)}{str(nc_tuple[0]).ljust(3)}: {str(nc_v).ljust(column_width)}{str(dc_tuple[0]).ljust(3)}: {str(dc_v).ljust(column_width)}{str(ac_tuple[0]).ljust(3)}: {str(ac_v).ljust(column_width)}\")\n",
    "print(\"_\" * ((5 * 4) + (column_width * 4)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Question 2\n",
    "\n",
    "2. *[20 marks] Obtain the three datasets in topic3networks.zip (under Topic 3 on Learn Ultra, see the descriptions below).  Load these networks.  Again, they are all undirected.  We wish also to work with connected graphs so find the largest connected component of each and discard other vertices.*\n",
    "*For each dataset, for each of the four centrality measures, list, in order, the 20 vertices with the highest values of that measure (include more if the values are tied).  Comment on whether you think, based on what you have found, that nearness centrality is a good alternative to closeness centrality and that adjacency centrality is a good alternative to degree centrality.*\n",
    "*The datasets:*\n",
    "\n",
    "* *london_transport_raw_edges.txt:  The network is of London rail and underground stations that are linked if they are adjacent on some line.  The second and third items on each line in the file are a pair of nodes that are joined by an edge (the first item describes how they are linked and can be ignored for this exercise).*\n",
    "* *Roget.txt: This is a network of words that are linked if they appear together in a thesaurus.  At the start of the file is a list of words (the nodes) and their numeric identifiers.    Then there are lists (one per line) of words that appear together in the thesaurus.  There should be an edge between any pair of nodes that appear in the same list.  For example, the list 3 4 323 325 implies the existence of six edges: (3,4), (3, 323), (3, 325), (4, 323), (4, 325), (323, 325)*\n",
    "* *CCSB-Y2H.txt: The network is of interactions amongst proteins in yeast (living cells can be considered as complex webs of macromolecular interactions known as interactome networks).  The first two items on each line are a pair of nodes joined by\n",
    "an edge (the rest of the line can be ignored).*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First we load the three graphs as adjancency lists."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported transport with 369 nodes.\n"
     ]
    }
   ],
   "source": [
    "transport = dict()\n",
    "with open(\"london_transport_raw_edges.txt\") as g:\n",
    "    for l in g:\n",
    "        data = l.split(\" \")\n",
    "        if data[1] not in transport:\n",
    "            transport[data[1]] = set()\n",
    "        if data[2][:-1] not in transport:\n",
    "            transport[data[2][:-1]] = set()\n",
    "\n",
    "        transport[data[1]].add(data[2][:-1])\n",
    "        transport[data[2][:-1]].add(data[1])\n",
    "\n",
    "print(f\"Imported transport with {len(transport)} nodes.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported thesaurus with 1022 nodes.\n"
     ]
    }
   ],
   "source": [
    "thesaurus = dict()\n",
    "thesaurus_names = dict()\n",
    "with open(\"Roget.txt\") as g:\n",
    "    for ln, l in enumerate(g):\n",
    "        if ln == 0 or ln == 1023:\n",
    "            continue\n",
    "        data = l.split(\" \")\n",
    "        if ln < 1023:\n",
    "            thesaurus[int(data[0])] = set()\n",
    "            thesaurus_names[int(data[0])] = data[1][:-1].replace(\"\\\"\", \"\")\n",
    "        if ln > 1023:\n",
    "            for node in data:\n",
    "                for u in data:\n",
    "                    if node == u:\n",
    "                        continue\n",
    "                    thesaurus[int(node)].add(int(u))\n",
    "                    thesaurus[int(u)].add(int(node))\n",
    "\n",
    "print(f\"Imported thesaurus with {len(thesaurus)} nodes.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported proteins with 1278 nodes.\n"
     ]
    }
   ],
   "source": [
    "proteins = dict()\n",
    "with open(\"CCSB-Y2H.txt\") as g:\n",
    "    for ln, l in enumerate(g):\n",
    "        if ln == 0:\n",
    "            continue\n",
    "        data = l.split(\"\\t\")\n",
    "        if data[0] not in proteins:\n",
    "            proteins[data[0]] = set()\n",
    "        if data[1] not in proteins:\n",
    "            proteins[data[1]] = set()\n",
    "        proteins[data[0]].add(data[1])\n",
    "        proteins[data[1]].add(data[0])\n",
    "\n",
    "print(f\"Imported proteins with {len(proteins)} nodes.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We reuse the connected components code from the first assignment."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def get_ccs(network: Dict[int, list[int]]) -> list[list[int]]:\n",
    "    ccs = []\n",
    "    nodes = set(list(network.keys()))\n",
    "    while nodes:\n",
    "        clear_output(wait=True)\n",
    "        print(f\"Current number of components: {len(ccs)}\")\n",
    "        print(f\"Unvisited nodes remaining: {len(nodes)}\")\n",
    "        node = nodes.pop()\n",
    "        node_reach = bfs(network, node)\n",
    "        ccs.append(node_reach.copy())\n",
    "        nodes = nodes.difference(node_reach)\n",
    "    return ccs\n",
    "\n",
    "\n",
    "def get_largest_vertex_set(vertex_sets: list[list[int]]) -> list[int]:\n",
    "    return max(vertex_sets, key=lambda k: len(k))\n",
    "\n",
    "\n",
    "def get_induced_subgraph(network: Dict[int, list[int]], vertex_set: list[int]) -> Dict[int, list[int]]:\n",
    "    induced_network = {}\n",
    "    for vertex in vertex_set:\n",
    "        induced_network[vertex] = network[vertex]\n",
    "    return induced_network"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest conected component in transport has 369 nodes.\n"
     ]
    }
   ],
   "source": [
    "transport_max = get_induced_subgraph(transport, get_largest_vertex_set(get_ccs(transport)))\n",
    "clear_output(wait=True)\n",
    "print(f\"Largest conected component in transport has {len(transport_max)} nodes.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest conected component in thesaurus has 994 nodes.\n"
     ]
    }
   ],
   "source": [
    "thesaurus_max = get_induced_subgraph(thesaurus, get_largest_vertex_set(get_ccs(thesaurus)))\n",
    "clear_output(wait=True)\n",
    "print(f\"Largest conected component in thesaurus has {len(thesaurus_max)} nodes.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest conected component in proteins has 964 nodes.\n"
     ]
    }
   ],
   "source": [
    "proteins_max = get_induced_subgraph(proteins, get_largest_vertex_set(get_ccs(proteins)))\n",
    "clear_output(wait=True)\n",
    "print(f\"Largest conected component in proteins has {len(proteins_max)} nodes.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We calculate the centrality measures of each vertex for all three datasets."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "centrality_measures = dict()\n",
    "\n",
    "for dataset in [\n",
    "    {\"name\": \"transport\", \"data\": transport_max,\n",
    "     \"dst_mat\": compute_dst_mat(transport_max)},\n",
    "    {\"name\": \"thesaurus\", \"data\": thesaurus_max,\n",
    "     \"dst_mat\": compute_dst_mat(thesaurus_max)},\n",
    "    {\"name\": \"proteins\", \"data\": proteins_max,\n",
    "     \"dst_mat\": compute_dst_mat(proteins_max)}\n",
    "]:\n",
    "    centrality_measures[dataset[\"name\"]] = dict()\n",
    "    for node in dataset[\"data\"]:\n",
    "        centrality_measures[dataset[\"name\"]][node] = dict()\n",
    "        centrality_measures[dataset[\"name\"]][node][\"cc\"] = cc(\n",
    "            dataset[\"dst_mat\"], node)\n",
    "        centrality_measures[dataset[\"name\"]][node][\"nc\"] = nc(\n",
    "            dataset[\"dst_mat\"], node)\n",
    "        centrality_measures[dataset[\"name\"]][node][\"dc\"] = dc(dataset[\"data\"], node)\n",
    "        centrality_measures[dataset[\"name\"]][node][\"ac\"] = ac(\n",
    "            dataset[\"data\"], node)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We then list the top 20 vertices (with ties) sorted each centrality measure for each dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "sorted_centrality_measures = dict()\n",
    "for dataset_name in [\"transport\", \"thesaurus\", \"proteins\"]:\n",
    "    sorted_centrality_measures[dataset_name] = dict()\n",
    "    for measure in [\"cc\", \"nc\", \"dc\", \"ac\"]:\n",
    "        sorted_centrality_measures[dataset_name][measure] = [\n",
    "            (v[0], v[1].get(measure)) for v in centrality_measures[dataset_name].items()]\n",
    "        sorted_centrality_measures[dataset_name][measure] = sorted(\n",
    "            sorted_centrality_measures[dataset_name][measure], key=lambda tup: tup[1], reverse=True)\n",
    "\n",
    "top_20_vertices = dict()\n",
    "for dataset_name in [\"transport\", \"thesaurus\", \"proteins\"]:\n",
    "    top_20_vertices[dataset_name] = {}\n",
    "    for measure in [\"cc\", \"nc\", \"dc\", \"ac\"]:\n",
    "        top_20_vertices[dataset_name][measure] = [v\n",
    "                                                  for v in sorted_centrality_measures[dataset_name][measure][:20]]\n",
    "        tie_measure_value = sorted_centrality_measures[dataset_name][measure][19][1]\n",
    "        ties = [v for i, v in enumerate(sorted_centrality_measures[dataset_name]\n",
    "                                        [measure]) if v[1] == tie_measure_value and i >= 20]\n",
    "        top_20_vertices[dataset_name][measure] += ties"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def print_measures(measures, thesaurus_lookup=False):\n",
    "    value_width = 10\n",
    "    vertex_width = 20\n",
    "    col_sep = 5\n",
    "    column_width = value_width + vertex_width + 2\n",
    "    print(\"_\" * ((column_width * 2) + col_sep))\n",
    "    print(\n",
    "        f\"{'CC'.center(column_width)}{' ' * col_sep}{'NC'.center(column_width)}\")\n",
    "    print(\"_\" * ((column_width * 2) + col_sep))\n",
    "    for i in range(max(len(measures[\"cc\"]), len(measures[\"nc\"]))):\n",
    "        if i >= len(measures[\"cc\"]):\n",
    "            cc_vertex = \"\"\n",
    "            cc_value = \"\"\n",
    "        else:\n",
    "            cc_tuple = measures[\"cc\"][i]\n",
    "            if thesaurus_lookup:\n",
    "                cc_vertex = str(thesaurus_names[cc_tuple[0]])[:vertex_width].ljust(vertex_width)\n",
    "            else:\n",
    "                cc_vertex = str(cc_tuple[0])[:vertex_width].ljust(vertex_width)\n",
    "            cc_value = format_number(cc_tuple[1]).ljust(value_width)\n",
    "        if i >= len(measures[\"nc\"]):\n",
    "            nc_vertex = \"\"\n",
    "            nc_value = \"\"\n",
    "        else:\n",
    "            nc_tuple = measures[\"nc\"][i]\n",
    "            if thesaurus_lookup:\n",
    "                nc_vertex = str(thesaurus_names[nc_tuple[0]])[:vertex_width].ljust(vertex_width)\n",
    "            else:\n",
    "                nc_vertex = str(nc_tuple[0])[:vertex_width].ljust(vertex_width)\n",
    "            nc_value = format_number(nc_tuple[1]).ljust(value_width)\n",
    "\n",
    "        print(f\"{cc_vertex}: {cc_value}{' ' * col_sep}{nc_vertex}: {nc_value}\")\n",
    "    print(\"_\" * ((column_width * 2) + col_sep))\n",
    "    print()\n",
    "    print(\"_\" * ((column_width * 2) + col_sep))\n",
    "    print(\n",
    "        f\"{'DC'.center(column_width)}{' ' * col_sep}{'AC'.center(column_width)}\")\n",
    "    print(\"_\" * ((column_width * 2) + col_sep))\n",
    "    for i in range(max(len(measures[\"dc\"]), len(measures[\"ac\"]))):\n",
    "        if i >= len(measures[\"dc\"]):\n",
    "            dc_vertex = \"\"\n",
    "            dc_value = \"\"\n",
    "        else:\n",
    "            dc_tuple = measures[\"dc\"][i]\n",
    "            if thesaurus_lookup:\n",
    "                dc_vertex = str(thesaurus_names[dc_tuple[0]])[:vertex_width].ljust(vertex_width)\n",
    "            else:\n",
    "                dc_vertex = str(dc_tuple[0])[:vertex_width].ljust(vertex_width)\n",
    "            dc_value = format_number(dc_tuple[1]).ljust(value_width)\n",
    "        if i >= len(measures[\"ac\"]):\n",
    "            ac_vertex = \"\"\n",
    "            ac_value = \"\"\n",
    "        else:\n",
    "            ac_tuple = measures[\"ac\"][i]\n",
    "            if thesaurus_lookup:\n",
    "                ac_vertex = str(thesaurus_names[ac_tuple[0]])[:vertex_width].ljust(vertex_width)\n",
    "            else:\n",
    "                ac_vertex = str(ac_tuple[0])[:vertex_width].ljust(vertex_width)\n",
    "            ac_value = format_number(ac_tuple[1]).ljust(value_width)\n",
    "\n",
    "        print(f\"{dc_vertex}: {dc_value}{' ' * col_sep}{ac_vertex}: {ac_value}\")\n",
    "\n",
    "    print(\"_\" * ((column_width * 2) + col_sep))\n",
    "    print(\"\\n\" * 3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initial measure investigation\n",
    "We first look at the measures on some simple graphs.."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________\n",
      "Graph                              DC             AC             \n",
      "____________________________________________________________\n",
      "Complete graph                      999.0          0.0           \n",
      "Complete graph + e (endpoint)       1.0           -0.998         \n",
      "Star graph (center)                 1000.0         0.998         \n",
      "Star graph (end-point)              1.0           -0.998         \n",
      "Cycle graph                         2.0            0.0           \n",
      "____________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n = 1000\n",
    "\n",
    "print_status_bar(0, block_count=80)\n",
    "\n",
    "k = dict()\n",
    "for i in range(n):\n",
    "    k[i] = set(range(n)).difference({i})\n",
    "\n",
    "print_status_bar(0.25, block_count=80)\n",
    "\n",
    "k_plus_e = {-1: {0}}\n",
    "for i in range(n):\n",
    "    k_plus_e[i] = set(range(n)).difference({i})\n",
    "\n",
    "print_status_bar(0.5, block_count=80)\n",
    "\n",
    "star_network = {-1: set(range(n))}\n",
    "for i in range(n):\n",
    "    star_network[i] = {-1}\n",
    "\n",
    "print_status_bar(0.75, block_count=80)\n",
    "c = dict()\n",
    "for i in range(n):\n",
    "    c[i] = {(i + 1) % n, (i - 1) % n}\n",
    "\n",
    "print_status_bar(0, block_count=80)\n",
    "clear_output(wait=True)\n",
    "\n",
    "column_width_large = 30\n",
    "column_width_small = 10\n",
    "column_sep = 5\n",
    "\n",
    "print(\"_\" * ((column_width_small * 2) + column_width_large + (2 * column_sep)))\n",
    "print(f\"{'Graph'.ljust(column_width_large)}{' ' * column_sep}\", end='')\n",
    "print(f\"{'DC'.ljust(column_width_small)}{' ' * column_sep}\", end='')\n",
    "print(f\"{'AC'.ljust(column_width_small)}{' ' * column_sep}\", end='')\n",
    "print()\n",
    "print(\"_\" * ((column_width_small * 2) + column_width_large + (2 * column_sep)))\n",
    "print(f\"{'Complete graph'.ljust(column_width_large)}{' ' * column_sep}\", end='')\n",
    "print(f\"{format_number(dc(k, 0)).ljust(column_width_small)}{' ' * column_sep}\", end='')\n",
    "print(f\"{format_number(ac(k, 0)).ljust(column_width_small)}{' ' * column_sep}\", end='')\n",
    "print()\n",
    "print(f\"{'Complete graph + e (endpoint)'.ljust(column_width_large)}{' ' * column_sep}\", end='')\n",
    "print(f\"{format_number(dc(k_plus_e, -1)).ljust(column_width_small)}{' ' * column_sep}\", end='')\n",
    "print(f\"{format_number(ac(k_plus_e, -1)).ljust(column_width_small)}{' ' * column_sep}\", end='')\n",
    "print()\n",
    "print(f\"{'Star graph (center)'.ljust(column_width_large)}{' ' * column_sep}\", end='')\n",
    "print(f\"{format_number(dc(star_network, -1)).ljust(column_width_small)}{' ' * column_sep}\", end='')\n",
    "print(f\"{format_number(ac(star_network, -1)).ljust(column_width_small)}{' ' * column_sep}\", end='')\n",
    "print()\n",
    "print(f\"{'Star graph (end-point)'.ljust(column_width_large)}{' ' * column_sep}\", end='')\n",
    "print(f\"{format_number(dc(star_network, 0)).ljust(column_width_small)}{' ' * column_sep}\", end='')\n",
    "print(f\"{format_number(ac(star_network, 0)).ljust(column_width_small)}{' ' * column_sep}\", end='')\n",
    "print()\n",
    "print(f\"{'Cycle graph'.ljust(column_width_large)}{' ' * column_sep}\", end='')\n",
    "print(f\"{format_number(dc(c, 0)).ljust(column_width_small)}{' ' * column_sep}\", end='')\n",
    "print(f\"{format_number(ac(c, 0)).ljust(column_width_small)}{' ' * column_sep}\", end='')\n",
    "print()\n",
    "print(\"_\" * ((column_width_small * 2) + column_width_large + (2 * column_sep)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now look at the top 20 nodes (including ties) for each of the datasets and measures."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________________________________________________\n",
      "               CC                                   NC               \n",
      "_____________________________________________________________________\n",
      "greenpark           :  0.000307      greenpark           :  59.5     \n",
      "westminster         :  0.000299      bank                :  59.3     \n",
      "bondstreet          :  0.000299      kingscrossstpancras :  58.7     \n",
      "kingscrossstpancras :  0.000299      bakerstreet         :  58.3     \n",
      "oxfordcircus        :  0.000298      oxfordcircus        :  57.8     \n",
      "bank                :  0.000295      waterloo            :  57.8     \n",
      "waterloo            :  0.000295      bondstreet          :  57.3     \n",
      "bakerstreet         :  0.000294      westminster         :  56.3     \n",
      "euston              :  0.000291      euston              :  55.7     \n",
      "victoria            :  0.00029       liverpoolstreet     :  55.2     \n",
      "farringdon          :  0.00029       shadwell            :  54.3     \n",
      "angel               :  0.00029       moorgate            :  54.2     \n",
      "hydeparkcorner      :  0.000288      highbury&islington  :  53.7     \n",
      "moorgate            :  0.000286      warrenstreet        :  53.3     \n",
      "barbican            :  0.000285      finchleyroad        :  53.3     \n",
      "oldstreet           :  0.000285      victoria            :  53.0     \n",
      "warrenstreet        :  0.000284      embankment          :  53.0     \n",
      "liverpoolstreet     :  0.000284      piccadillycircus    :  52.7     \n",
      "highbury&islington  :  0.000284      tottenhamcourtroad  :  52.4     \n",
      "eustonsquare        :  0.000284      regentspark         :  52.3     \n",
      "piccadillycircus    :  0.000284      : \n",
      "_____________________________________________________________________\n",
      "\n",
      "_____________________________________________________________________\n",
      "               DC                                   AC               \n",
      "_____________________________________________________________________\n",
      "kingscrossstpancras :  7.0           paddington          :  0.48     \n",
      "bakerstreet         :  7.0           stratford           :  0.475    \n",
      "stratford           :  7.0           kingscrossstpancras :  0.46     \n",
      "oxfordcircus        :  6.0           bakerstreet         :  0.453    \n",
      "greenpark           :  6.0           canningtown         :  0.417    \n",
      "paddington          :  6.0           blackhorseroad      :  0.4      \n",
      "waterloo            :  6.0           stockwell           :  0.4      \n",
      "bank                :  6.0           chalfont&latimer    :  0.4      \n",
      "earlscourt          :  6.0           willesdenjunction   :  0.365    \n",
      "westham             :  6.0           earlscourt          :  0.339    \n",
      "canningtown         :  6.0           westham             :  0.321    \n",
      "euston              :  5.0           surreyquays         :  0.317    \n",
      "willesdenjunction   :  5.0           shadwell            :  0.309    \n",
      "liverpoolstreet     :  5.0           finchleycentral     :  0.3      \n",
      "shadwell            :  5.0           sydenham            :  0.3      \n",
      "turnhamgreen        :  5.0           turnhamgreen        :  0.294    \n",
      "camdentown          :  4.0           waterloo            :  0.289    \n",
      "highbury&islington  :  4.0           nottinghillgate     :  0.286    \n",
      "tottenhamcourtroad  :  4.0           holborn             :  0.25     \n",
      "piccadillycircus    :  4.0           finsburypark        :  0.25     \n",
      "bondstreet          :  4.0           wembleypark         :  0.25     \n",
      "holborn             :  4.0           westhampstead       :  0.25     \n",
      "finsburypark        :  4.0           : \n",
      "shepherdsbush       :  4.0           : \n",
      "leicestersquare     :  4.0           : \n",
      "westminster         :  4.0           : \n",
      "victoria            :  4.0           : \n",
      "moorgate            :  4.0           : \n",
      "embankment          :  4.0           : \n",
      "finchleyroad        :  4.0           : \n",
      "nottinghillgate     :  4.0           : \n",
      "westbrompton        :  4.0           : \n",
      "wembleypark         :  4.0           : \n",
      "westhampstead       :  4.0           : \n",
      "londonbridge        :  4.0           : \n",
      "blackhorseroad      :  4.0           : \n",
      "stockwell           :  4.0           : \n",
      "whitechapel         :  4.0           : \n",
      "mileend             :  4.0           : \n",
      "actontown           :  4.0           : \n",
      "canadawater         :  4.0           : \n",
      "surreyquays         :  4.0           : \n",
      "canarywharf         :  4.0           : \n",
      "poplar              :  4.0           : \n",
      "_____________________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_measures(top_20_vertices[\"transport\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________________________________________________\n",
      "               CC                                   NC               \n",
      "_____________________________________________________________________\n",
      "inutility           :  0.000496      inutility           :  540.0    \n",
      "store               :  0.000491      neglect             :  534.0    \n",
      "neglect             :  0.00049       deterioration       :  533.0    \n",
      "deterioration       :  0.00049       truth               :  530.0    \n",
      "truth               :  0.000489      store               :  527.0    \n",
      "unimportance        :  0.000489      unimportance        :  526.0    \n",
      "unconformity        :  0.000488      indication          :  525.0    \n",
      "support             :  0.000487      support             :  524.0    \n",
      "indication          :  0.000484      inactivity          :  523.0    \n",
      "inactivity          :  0.000484      activity            :  523.0    \n",
      "deception           :  0.000482      deception           :  523.0    \n",
      "activity            :  0.000481      aid                 :  521.0    \n",
      "aid                 :  0.000481      unconformity        :  521.0    \n",
      "restraint           :  0.000481      restraint           :  516.0    \n",
      "care                :  0.00048       care                :  516.0    \n",
      "skill               :  0.000478      information         :  515.0    \n",
      "information         :  0.000477      obstinacy           :  515.0    \n",
      "preparation         :  0.000477      skill               :  514.0    \n",
      "plan                :  0.000475      pleasurableness     :  514.0    \n",
      "hindrance           :  0.000475      uncertainty         :  513.0    \n",
      "_____________________________________________________________________\n",
      "\n",
      "_____________________________________________________________________\n",
      "               DC                                   AC               \n",
      "_____________________________________________________________________\n",
      "inutility           :  145.0         indication          :  0.475    \n",
      "deterioration       :  136.0         deterioration       :  0.449    \n",
      "neglect             :  135.0         inutility           :  0.446    \n",
      "truth               :  128.0         store               :  0.444    \n",
      "activity            :  123.0         neglect             :  0.436    \n",
      "indication          :  123.0         truth               :  0.414    \n",
      "deception           :  121.0         support             :  0.411    \n",
      "inactivity          :  119.0         pleasurableness     :  0.399    \n",
      "obstinacy           :  118.0         obstinacy           :  0.397    \n",
      "unimportance        :  117.0         unconformity        :  0.394    \n",
      "store               :  117.0         inactivity          :  0.39     \n",
      "aid                 :  116.0         aid                 :  0.383    \n",
      "support             :  116.0         activity            :  0.375    \n",
      "destruction         :  110.0         deception           :  0.371    \n",
      "uncertainty         :  109.0         information         :  0.366    \n",
      "pleasurableness     :  109.0         destruction         :  0.362    \n",
      "information         :  108.0         restraint           :  0.362    \n",
      "error               :  105.0         unimportance        :  0.36     \n",
      "skill               :  105.0         painfulness         :  0.357    \n",
      "care                :  105.0         junction            :  0.347    \n",
      "restraint           :  105.0         : \n",
      "_____________________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_measures(top_20_vertices[\"thesaurus\"], thesaurus_lookup=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________________________________________________\n",
      "               CC                                   NC               \n",
      "_____________________________________________________________________\n",
      "YLR291C             :  0.000336      YLR291C             :  385.0    \n",
      "YBR261C             :  0.000297      YLR423C             :  327.0    \n",
      "YPL070W             :  0.000295      YBR261C             :  325.0    \n",
      "YCL028W             :  0.000292      YPL070W             :  316.0    \n",
      "YPL049C             :  0.000289      YPL049C             :  310.0    \n",
      "YLR423C             :  0.000289      YCL028W             :  305.0    \n",
      "YNL044W             :  0.000283      YHR113W             :  298.0    \n",
      "YHR113W             :  0.000282      YDR510W             :  297.0    \n",
      "YOR284W             :  0.000282      YNL044W             :  296.0    \n",
      "YLR245C             :  0.00028       YOR284W             :  294.0    \n",
      "YBR080C             :  0.000279      YKR034W             :  294.0    \n",
      "YPL088W             :  0.000278      YLR245C             :  291.0    \n",
      "YGR267C             :  0.000277      YDL239C             :  291.0    \n",
      "YHL018W             :  0.000277      YGL153W             :  290.0    \n",
      "YBR233W             :  0.000276      YPL088W             :  289.0    \n",
      "YMR095C             :  0.000276      YBR080C             :  289.0    \n",
      "YDR256C             :  0.000276      YNL229C             :  288.0    \n",
      "YOR095C             :  0.000275      YHL018W             :  288.0    \n",
      "YHR112C             :  0.000275      YMR095C             :  287.0    \n",
      "YKR034W             :  0.000275      YOL034W             :  287.0    \n",
      "_____________________________________________________________________\n",
      "\n",
      "_____________________________________________________________________\n",
      "               DC                                   AC               \n",
      "_____________________________________________________________________\n",
      "YLR291C             :  86.0          YCR106W             :  0.892    \n",
      "YLR423C             :  58.0          YIR038C             :  0.876    \n",
      "YIR038C             :  51.0          YML051W             :  0.865    \n",
      "YBR261C             :  42.0          YLR423C             :  0.856    \n",
      "YDR510W             :  40.0          YLR291C             :  0.848    \n",
      "YDR479C             :  36.0          YDR510W             :  0.832    \n",
      "YDR100W             :  30.0          YDL100C             :  0.832    \n",
      "YML051W             :  29.0          YDR479C             :  0.79     \n",
      "YPL094C             :  28.0          YPL094C             :  0.747    \n",
      "YPL049C             :  27.0          YMR070W             :  0.722    \n",
      "YPL070W             :  27.0          YBR261C             :  0.72     \n",
      "YAR027W             :  25.0          YPL004C             :  0.719    \n",
      "YNL189W             :  22.0          YDR100W             :  0.665    \n",
      "YDL100C             :  22.0          YAR027W             :  0.644    \n",
      "YDR448W             :  21.0          YER125W             :  0.629    \n",
      "YCR106W             :  20.0          YIR033W             :  0.625    \n",
      "YKR034W             :  19.0          YDR448W             :  0.617    \n",
      "YML029W             :  17.0          YKL117W             :  0.615    \n",
      "YIR033W             :  17.0          YML029W             :  0.59     \n",
      "YHR113W             :  16.0          YJL019W             :  0.585    \n",
      "_____________________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_measures(top_20_vertices[\"proteins\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Adjacency centrality vs degree centrality\n",
    "We see that adjacency centrality gives us a notion of how *popular* (that is, the degree centrality) a node in context to its neighbours. A node with high adjacency centrality has a higher popularity compared to its neighbours (on average), while a node with a low adjacency centrality has a lower popularity compared to its neighbours (on average). In contrast, degree centrality has a more localised view, giving only the absolute *popularity* of a node. The best of the two measures depends on how the *influence* of a node is to be decided. For example, in the transport dataset it could be said that adjacency centrality is a more useful measure as it gives you a feel for which nodes may be treated as *hubs*; that is, a node in which people commute to and from on the way to another node (although a measure such as betweenness centrality may do this more aptly). In general, adjacency centrality seems to be a better measure in a context such as flow networks, while degree centrality is more suited in situations where you want to select nodes with a high popularity, such as in a graph SIR model (see next assignment)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Nearness centrality vs closeness centrality\n",
    "Closeness centrality gives us the average shortest path from a node to all other nodes. Nearness centrality (otherwise known as harmonic centrality) is a variant of closeness centrality that was devised to help when dealing with disconnected graphs (that is, a graph in which some nodes are unreachable from a given start node). To see this, we define $1/d_{ij}$ to be $0$ if there is no path from $i$ to $j$. In the datasets given, we are working with the largest connected component, so this benefit does not help. We can draw more distinctions between these measures. We can think of calculating nearness centrality as a *scoring* process, for every node that is close to the node we are calculating nearness centrality for, we add the reciprocal of its distance to the total score, doing this for every other node. Here we see that a node is not punished for having a node that it has a large shortest path to, it simply gets a small score added on. In comparison, closeness centrality *does* punish such long shortest paths as it is computing the average shortest path length. Thus one may pick nearness centrality if we are favouring nodes that have a lot of close nodes, while one may pick closeness centrality if we want the node to be (on average) close to all nodes."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Ben Napier"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}